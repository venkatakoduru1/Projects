# ğŸ‘‹ Karthik Koduru | Computer Vision & Robotics Engineer  

ğŸ”¬ **Graduate Research Assistant - Monocular Depth Estimation**  
ğŸ“ **M.S. in Robotics (ECE) | Northeastern University**  
ğŸ“ **Boston, MA** | Open to Relocation  

## ğŸš€ About Me  
I am a **Computer Vision & Robotics Engineer** with expertise in **deep learning, perception, and real-time AI systems**. My work focuses on **monocular depth estimation, object tracking, autonomous systems, and assistive vision applications**. I have a strong background in **transformer-based models (ViTs, DepthAnything V2), simulation (CARLA, ROS, Gazebo), and real-time deep learning solutions**.  

This repository showcases my **top projects**, where I implement **cutting-edge AI and robotics techniques** to solve real-world challenges.  

---

## ğŸ“‚ Featured Projects  

### **1ï¸âƒ£ Real-Time ADAS Simulation for LiDAR-Based Object Detection & Tracking**  
**ğŸ”¹ Description:**  
- This project simulates **50+ autonomous driving scenarios** in **CARLA** to evaluate an object detection and tracking algorithm based on **optical flow**.  
- The model was **validated on the KITTI dataset** to assess real-world generalization.  
- **Enhanced trajectory tracking accuracy to 92%** while **reducing velocity estimation errors by 12%**.  
- Developed a **PID-based collision avoidance system** with a **98% success rate** in real-world simulations.  

**ğŸ”§ Tools & Technologies:** Python, OpenCV, CARLA, NumPy, KITTI Dataset  

ğŸ”— **[Project Repository](#)** (Replace `#` with actual link)  

---

### **2ï¸âƒ£ Real-Time Assistive Vision App for the Visually Impaired**  
**ğŸ”¹ Description:**  
- Developed an **AI-powered mobile application** that integrates **object detection and monocular depth estimation** to assist visually impaired users.  
- Implemented a **robust backend pipeline** to handle computationally intensive tasks efficiently.  
- Integrated **natural language processing (NLP) for intelligent interaction**, enhancing accessibility.  
- Achieved **seamless real-time depth estimation** using **DepthAnything V2 and YOLO (v5/v8)**.  

**ğŸ”§ Tools & Technologies:** Python, OpenCV, PyTorch, YOLOv5/YOLOv8, DepthAnything V2, Flask, Yapper-TTS, LLaMA 3 (7B) via Groq API  

ğŸ”— **[Project Repository](#)**  

---

### **3ï¸âƒ£ AI-Driven Workout Assistant | Pose Detection & Analysis**  
**ğŸ”¹ Description:**  
- Developed a **BiLSTM-based pose estimation model** that achieves **98.3% accuracy**, improving **workout posture correction & injury prevention**.  
- Designed a **real-time feedback system** that **reduces response latency to 150ms**, ensuring a seamless user experience.  
- Integrated **real-time physiotherapy tracking**, boosting correction feedback effectiveness by **40%**, enhancing rehabilitation programs.  

**ğŸ”§ Tools & Technologies:** Python, TensorFlow, MoveNet, Decision Trees, KNN, LSTM, BiLSTM  

ğŸ”— **[Project Repository](#)**  

---

### **4ï¸âƒ£ Hybrid Deep Learning for Color Constancy (CNN & GANs)**  
**ğŸ”¹ Description:**  
- Explored **24 CNN models** with hyperparameter tuning to **reduce mean angular error by 15%**, improving color constancy across varying lighting conditions.  
- Designed a **hybrid CNN-GAN model** to enhance **white balance accuracy**, reducing angular error by **20% in complex illumination scenarios**.  
- This project applies **deep learning for image enhancement**, critical for **computer vision applications in photography, robotics, and medical imaging**.  

**ğŸ”§ Tools & Technologies:** Python, OpenCV, PyTorch, NumPy  

ğŸ”— **[Project Repository](#)**  

---

### **5ï¸âƒ£ Computer Vision-Based Servo Tracking System**  
**ğŸ”¹ Description:**  
- Built a **real-time servo tracking system** that achieves **95% accuracy** with a latency of **100ms** and an **angular error of just 2.5Â°**.  
- Integrated **object and facial recognition** (92% precision, 8% error rate), enabling **dynamic servo adjustments for real-time object tracking**.  
- Ideal for **robotic vision systems, automated surveillance, and smart camera applications**.  

**ğŸ”§ Tools & Technologies:** Python, ROS, OpenCV, Arduino  

ğŸ”— **[Project Repository](#)**  

---

## ğŸ“š Tech Stack  

ğŸ”¹ **Programming:** Python, C++, Java, Bash  
ğŸ”¹ **Deep Learning & CV:** PyTorch, TensorFlow, OpenCV, DepthAnything V2, ViTs (ViT-S, ViT-L), DINO, SAM  
ğŸ”¹ **Simulation & Robotics:** ROS, Gazebo, CARLA, MATLAB  
ğŸ”¹ **Cloud & DevOps:** Docker, Jenkins, IBM Cloud, AWS  

---

## ğŸ“¬ Get in Touch  
ğŸ“§ **Email:** koduru.ve@northeastern.edu  
ğŸ”— **LinkedIn:** [linkedin.com/in/kodurukarthik](#)  
ğŸ”— **GitHub:** [github.com/venkatakoduru1](#)  

---

## â­ Contributing  
If you find my work interesting, **feel free to star the repository ğŸŒŸ, fork it, or open an issue**. Contributions and collaborations are always welcome!  

---

## ğŸ“œ License  
This repository is licensed under the **MIT License** â€“ feel free to use and improve the code with proper attribution.  

---

## ğŸ”¥ Final Thoughts  
This **GitHub README** makes it **clear, structured, and appealing to recruiters & collaborators**. ğŸš€  

Let me know if you need any refinements before you upload it! ğŸ˜Š  
